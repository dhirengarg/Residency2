{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IEJOH3pMy_EG"
   },
   "source": [
    "\n",
    "\n",
    "## Lab 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yRG2Rb6By_EK"
   },
   "source": [
    "Welcome to the second lab of the AIML!\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the lab and your implementation. Each question you will answer is preceded by a **'Question X'** header. Carefully read each question and provide you answer or code in the following textboxes with **'Answer:'** header. Your lab submission will be evaluated based on your answers to each of the questions and the implementation you provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wv9-kA4vy_EN"
   },
   "source": [
    "# Every question is of 1 mark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7F5I7f9y_EQ"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DbanWtFwzc-A"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import scipy.stats as stats\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s3TbncQ0y_ES"
   },
   "source": [
    "This module covers,\n",
    "\n",
    "1) One sample and Two sample t-tests\n",
    "\n",
    "2) ANOVA\n",
    "\n",
    "3) Type I and Type II errors\n",
    "\n",
    "4) Probabilty Distributions\n",
    "\n",
    "5) Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i8UE0UE6y_EV"
   },
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kImA4Gk-y_EW"
   },
   "source": [
    "The purpose of the test is to tell if there is any significant difference between two data sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yItvHo3By_EZ"
   },
   "source": [
    "## Question 1 \n",
    "\n",
    "*A student is trying to decide between two GPUs. He want to use the GPU for his research to run Deep learning algorithms, so the only thing he is concerned with is speed.*\n",
    "\n",
    "*He picks a Deep Learning algorithm on a large data set and runs it on both GPUs 15 times, timing each run in hours. Results are given in the below lists GPU1 and GPU2.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nnQ2Ftdgy_Ea"
   },
   "source": [
    "Hint: You can import ttest function from scipy to perform t tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbQ05nufy_Ec"
   },
   "source": [
    "Given,\n",
    "\n",
    "Null Hypothesis : There is no significant difference between data sets\n",
    "\n",
    "Alternate Hypothesis : There is a significant difference\n",
    "\n",
    "*Do two-sample testing and check whether to reject Null Hypothesis or not.*\n",
    "\n",
    "#### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zg9r4020y_Ee"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "GPU1 = pd.DataFrame([11,9,10,11,10,12,9,11,12,9,11,12,9,10,9])\n",
    "GPU2 = pd.DataFrame([11,13,10,13,12,9,11,12,12,11,12,12,10,11,13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Value 0.014\n"
     ]
    }
   ],
   "source": [
    "Diff =  GPU1 - GPU2\n",
    "t_statistic, p_value  =  stats.ttest_ind(GPU1,GPU2)\n",
    "print('P Value %1.3f' % p_value)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since p value is < .05 then we reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VqYtQt37y_El"
   },
   "source": [
    "[## Question 2 \n",
    "](https://)\n",
    "He is trying a third GPU which is GPU3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JM3dI6Kpy_Eo"
   },
   "outputs": [],
   "source": [
    "GPU3 = pd.DataFrame([9,10,9,11,10,13,12,9,12,12,13,12,13,10,11])\n",
    "\n",
    "#Assumption: Both the datasets (GPU1 & GPU 3) are random, independent, parametric & normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Value 0.145\n"
     ]
    }
   ],
   "source": [
    "Diff1 = GPU3 - GPU1\n",
    "t_statistic, p_value  =  stats.ttest_ind(GPU1,GPU3)\n",
    "print('P Value %1.3f' % p_value)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Answer: Since p value is > .05 then we fail to reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xccR5TB4y_Ev"
   },
   "source": [
    "*Do two-sample testing and check whether there is significant differene between speeds of two GPUs GPU1 and GPU3.*\n",
    "\n",
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ntmaD07y_E2"
   },
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G0pj7K4jy_E4"
   },
   "source": [
    "## Question 3 \n",
    "\n",
    "If you need to compare more than two data sets at a time, an ANOVA is your best bet. \n",
    "\n",
    "*The results from three experiments with overlapping 95% confidence intervals are given below, and we want to confirm that the results for all three experiments are not significantly different.*\n",
    "\n",
    "#Assumption: All the 3 datasets (e1,e2 & e3) are random, independent, parametric & normally distributed\n",
    "But before conducting ANOVA, test equality of variances (using Levene's test) is satisfied or not. If not, then mention that we cannot depend on the result of ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AKzdGmBWy_E7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "e1 = pd.DataFrame([1.595440,1.419730,0.000000,0.000000])\n",
    "e2 = pd.DataFrame([1.433800,2.079700,0.892139,2.384740])\n",
    "e3 = pd.DataFrame([0.036930,0.938018,0.995956,1.006970])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iZ5OpNTZy_FH"
   },
   "source": [
    "Hint - You can use stats.levene function and stats.f_oneway function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LS7fFigZy_FM"
   },
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JeTpweFsy_FP",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=array([2.67417257]), pvalue=array([0.12259793]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.levene(e1,e2,e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we fail to reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=array([2.51357623]), pvalue=array([0.13574645]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.f_oneway(e1,e2,e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we fail to reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-QkO7Zdky_FY"
   },
   "source": [
    "## Question 4 \n",
    "\n",
    "*In one or two sentences explain about **TypeI** and **TypeII** errors.*\n",
    "\n",
    "#### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7GMrA5hiy_Fc"
   },
   "outputs": [],
   "source": [
    "## Type1 Error \n",
    "## When the null hypothesis is true and you reject it, you make a type\n",
    "## I error. The probability of making a type I error is α, which is the level \n",
    "## of significance you set for your hypothesis test. An α of 0.05 indicates \n",
    "## that you are willing to accept a 5% chance that you are wrong when you reject \n",
    "## the null hypothesis. To lower this risk, you must use a lower value for α. \n",
    "## However, using a lower value for alpha means that you will be less likely \n",
    "##  to detect a true difference if one really exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6x2cZFpyy_Fi"
   },
   "outputs": [],
   "source": [
    "## type II error \n",
    "## When the null hypothesis is false and you fail to reject it,\n",
    "## you make a type II error. The probability of making a type II \n",
    "## error is β, which depends on the power of the test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HjY6P__6y_Fm"
   },
   "source": [
    "# Question 5\n",
    "You are a manager of a chinese restaurant. You want to determine whether the waiting time to place an order has changed in the past month from its previous population mean value of 4.5 minutes. \n",
    "State the null and alternative hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lV5GQ6T8y_Fp"
   },
   "source": [
    "* $H_0$ >= 4.5   \n",
    "* $H_a$ < 4.5    Alternate Hypothesis is to check whether there is change in mean waiting time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gflwdh5qy_F4"
   },
   "source": [
    "# Question 6 \n",
    "Get the binomial distribution with n = 10, p = .7 and k = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "Hint - Use stats.binom.pmf() function for this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u43Z8ZM-y_F5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.90490000e-06, 1.37781000e-04, 1.44670050e-03, 9.00169200e-03,\n",
       "       3.67569090e-02, 1.02919345e-01, 2.00120949e-01, 2.66827932e-01])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "p = .7\n",
    "k = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "bio = stats.binom.pmf(k,n,p)\n",
    "bio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D5whZ6A5y_F9"
   },
   "source": [
    "# Question 7 \n",
    "Plot the distribution created in the above question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emY4gr4Jy_F_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 8 artists>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(k, bio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wMKyZctHy_GE"
   },
   "source": [
    "# Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LDJS2-Pgy_GH"
   },
   "source": [
    "# Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aXhBleCy_GM"
   },
   "source": [
    "Here we will try to see that if we can make a regression model to predict one column of a dataset by the use of other coloumn.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Population of U.S. Cities\n",
    "\n",
    "### Description\n",
    "The bigcity data frame has 49 rows and 2 columns.\n",
    "\n",
    "The measurements are the population (in 1000's) of 49 U.S. cities in 1920 and 1930. The 49 cities are a random sample taken from the 196 largest cities in 1920.\n",
    "\n",
    "### Format\n",
    "This data frame contains the following columns:\n",
    "\n",
    "`u`\n",
    "The 1920 population.\n",
    "\n",
    "`x`\n",
    "The 1930 population.\n",
    "\n",
    "There is one unnamed column also in this dataset. Please remove and ignore that coloumn.\n",
    "\n",
    "Source\n",
    "\n",
    "The data were obtained from\n",
    "\n",
    "Cochran, W.G. (1977) Sampling Techniques. Third edition. John Wiley\n",
    "\n",
    "References\n",
    "\n",
    "Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application. Cambridge University Press."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jR6a2l7my_GO"
   },
   "source": [
    "# Question 8 \n",
    "Read the dataset given in file named 'bigcity.csv'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2syrwIZey_GQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>u</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>179</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>71</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>298</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>74</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>381</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>387</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>78</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>507</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>77</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>136</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>243</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>256</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>94</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>120</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>172</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>66</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>46</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>121</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>64</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>56</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>116</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>87</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>43</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>161</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0    u    x\n",
       "0            1  138  143\n",
       "1            2   93  104\n",
       "2            3   61   69\n",
       "3            4  179  260\n",
       "4            5   48   75\n",
       "5            6   37   63\n",
       "6            7   29   50\n",
       "7            8   23   48\n",
       "8            9   30  111\n",
       "9           10    2   50\n",
       "10          11   38   52\n",
       "11          12   46   53\n",
       "12          13   71   79\n",
       "13          14   25   57\n",
       "14          15  298  317\n",
       "15          16   74   93\n",
       "16          17   50   58\n",
       "17          18   76   80\n",
       "18          19  381  464\n",
       "19          20  387  459\n",
       "20          21   78  106\n",
       "21          22   60   57\n",
       "22          23  507  634\n",
       "23          24   50   64\n",
       "24          25   77   89\n",
       "25          26   64   77\n",
       "26          27   40   60\n",
       "27          28  136  139\n",
       "28          29  243  291\n",
       "29          30  256  288\n",
       "30          31   94   85\n",
       "31          32   36   46\n",
       "32          33   45   53\n",
       "33          34   67   67\n",
       "34          35  120  115\n",
       "35          36  172  183\n",
       "36          37   66   86\n",
       "37          38   46   65\n",
       "38          39  121  113\n",
       "39          40   44   58\n",
       "40          41   64   63\n",
       "41          42   56  142\n",
       "42          43   40   64\n",
       "43          44  116  130\n",
       "44          45   87  105\n",
       "45          46   43   61\n",
       "46          47   43   50\n",
       "47          48  161  232\n",
       "48          49   36   54"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bigcity.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z2xteyYby_GT"
   },
   "source": [
    "# Question 9 - Transform the dataset \n",
    "Find the number of rows in given dataset and separate the input(u column)  and target variables(x column) into X and Y.\n",
    "\n",
    "Remove the unnamed coloumn.\n",
    "\n",
    "Hint: You can shape function to get the size of the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7KJUYwDMy_GX",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 1)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X =df.u\n",
    "X1 = X.values.reshape(-1,1)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 1)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y =df.x\n",
    "Y1 = Y.values.reshape(-1,1)\n",
    "Y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>179</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>38</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>71</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>298</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>74</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>381</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>387</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>78</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>507</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>136</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>243</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>256</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>94</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>45</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>120</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>172</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>66</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>46</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>121</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>44</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>64</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>56</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>116</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>87</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>43</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>161</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>36</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      u    x\n",
       "0   138  143\n",
       "1    93  104\n",
       "2    61   69\n",
       "3   179  260\n",
       "4    48   75\n",
       "5    37   63\n",
       "6    29   50\n",
       "7    23   48\n",
       "8    30  111\n",
       "9     2   50\n",
       "10   38   52\n",
       "11   46   53\n",
       "12   71   79\n",
       "13   25   57\n",
       "14  298  317\n",
       "15   74   93\n",
       "16   50   58\n",
       "17   76   80\n",
       "18  381  464\n",
       "19  387  459\n",
       "20   78  106\n",
       "21   60   57\n",
       "22  507  634\n",
       "23   50   64\n",
       "24   77   89\n",
       "25   64   77\n",
       "26   40   60\n",
       "27  136  139\n",
       "28  243  291\n",
       "29  256  288\n",
       "30   94   85\n",
       "31   36   46\n",
       "32   45   53\n",
       "33   67   67\n",
       "34  120  115\n",
       "35  172  183\n",
       "36   66   86\n",
       "37   46   65\n",
       "38  121  113\n",
       "39   44   58\n",
       "40   64   63\n",
       "41   56  142\n",
       "42   40   64\n",
       "43  116  130\n",
       "44   87  105\n",
       "45   43   61\n",
       "46   43   50\n",
       "47  161  232\n",
       "48   36   54"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TyuhJDK5y_Gc"
   },
   "source": [
    "## Question 10 - Check the dataset for any missing values and also print out the correlation matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpzkRe81y_Gd",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.981742</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          u         x\n",
       "u  1.000000  0.981742\n",
       "x  0.981742  1.000000"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fMy6zL1Ky_Gh"
   },
   "source": [
    "You can use .isna() and .corr() functions to check NA's and correlation in the dataframe respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O05wXnYhy_Gs"
   },
   "source": [
    "### The high correlation betwwen u and x indicates that the variable u is a good predictor of variable x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWu2j-iFy_Gt"
   },
   "source": [
    "# Question 11 - Split data into train, test sets \n",
    "Divide the data into training and test sets with 80-20 split using scikit-learn. Print the shapes of training and test feature sets.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2xGeBU-Fy_Gv"
   },
   "source": [
    "Check: train_test_split function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uKcfywXEy_Gw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 1)\n",
      "(39, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.20, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tejO-bEhy_Gz"
   },
   "source": [
    "# Question 12 - Find coefficients & intercept\n",
    "Estimate the coefficients b0 and b1 using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hvex1b0ly_G2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient is 1.1594512342174779\n",
      "intercept is 9.718455322828262\n"
     ]
    }
   ],
   "source": [
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_train, y_train)\n",
    "print(\"coefficient is \"   + str(regression_model.coef_[0][0]))\n",
    "print(\"intercept is \" + str(regression_model.intercept_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p0TWJsooy_HA"
   },
   "source": [
    "Check: coef_ and intercept_ functions can help you get coefficients & intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LhtToZvAy_HB"
   },
   "source": [
    "# Question 13 - Linear Relationship between feature and target \n",
    "Plot the line with b1 and b0 as slope and y-intercept.\n",
    "\n",
    "Hint - y = mx + c, plot y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-9CG10Evy_HD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x178998d9978>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_y_train =  regression_model.coef_[0][0]*X_train + regression_model.intercept_[0]\n",
    "plt.plot(X_train,pred_y_train)\n",
    "plt.scatter(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZxObh5Wy_HG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ji-pKQMty_HJ"
   },
   "source": [
    "# Question 14 - Evaluation of model with scikit-learn \n",
    "Validate the model with Root Mean Squares error and R^2 score using scikit-learn. RMSE and R2 for test data and prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CwT09ICUy_HK"
   },
   "source": [
    "Hint: You can import mean_squared_error function & r2 (R square) from sklearn.metrics. Performing root operation over mean square error over mean square error gives you root mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCJnyT_py_HL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.385235190249123"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = regression_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "rmse = sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFiUy7z2y_HT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9682175540860046"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9682175540860046"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_train, pred_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1YTkh9Fgy_HX"
   },
   "source": [
    "## Question 15 - Calculate the accuracy of the model for both training and test data set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ZUDAcG-y_HX"
   },
   "source": [
    "### Hint: .score() function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HVOq2k33y_HY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9181922560396981"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEUJL7-Qy_Hc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9150786863461885"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRGRNbqay_Hi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "InternalLab_Residency2_Hypothesis_Testing_and_Linear_Regression-updated.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
